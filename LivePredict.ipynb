{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7f7b4bf-d259-4bd0-96ec-08fdedb6083b",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72995b05-a522-443c-b562-acd98c4c341a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from ultralytics import YOLO\n",
    "\n",
    "os.environ['OPENCV_FFMPEG_CAPTURE_OPTIONS'] = 'rtsp_transport;udp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8532966c-f36d-4810-a393-ec534b04322c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = r\"./runs/detect/train/weights/best.pt\"\n",
    "video_path = r\"C:\\Users\\ChenYi\\Desktop\\CV\\datasets\\videos\\video_timelapse.mp4\"\n",
    "rtsp = \"rtsp://camera_username:camera_password@192.168.68.60:554/stream1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63bb21f-7fd4-463e-ba3c-5709e0400811",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac636909-412f-4831-bef2-c72959037793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model\n",
    "model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "613b3a05-b5ff-4d1d-81c1-db0c18038752",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 47.1ms\n",
      "Speed: 7.7ms preprocess, 47.1ms inference, 46.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 2.9ms preprocess, 11.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.0ms preprocess, 11.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 1.0ms preprocess, 11.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 1.0ms preprocess, 11.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.7ms\n",
      "Speed: 0.0ms preprocess, 9.7ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.3ms\n",
      "Speed: 1.9ms preprocess, 7.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 6.5ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 16.4ms\n",
      "Speed: 0.0ms preprocess, 16.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.3ms\n",
      "Speed: 2.0ms preprocess, 12.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.2ms\n",
      "Speed: 1.7ms preprocess, 12.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 3.5ms preprocess, 11.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.0ms\n",
      "Speed: 3.8ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.0ms\n",
      "Speed: 5.4ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 18.8ms\n",
      "Speed: 0.0ms preprocess, 18.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.0ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 7.8ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.9ms\n",
      "Speed: 2.0ms preprocess, 10.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.1ms\n",
      "Speed: 1.0ms preprocess, 8.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.1ms\n",
      "Speed: 0.0ms preprocess, 15.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.3ms\n",
      "Speed: 0.0ms preprocess, 14.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.7ms\n",
      "Speed: 4.1ms preprocess, 9.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.3ms\n",
      "Speed: 0.5ms preprocess, 12.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 15.3ms\n",
      "Speed: 0.0ms preprocess, 15.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 2.0ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 0.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 1.1ms preprocess, 11.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.7ms\n",
      "Speed: 2.1ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 6.8ms preprocess, 12.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 1.7ms preprocess, 11.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.9ms\n",
      "Speed: 2.0ms preprocess, 11.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.2ms\n",
      "Speed: 1.0ms preprocess, 5.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 4.9ms\n",
      "Speed: 1.1ms preprocess, 4.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.7ms\n",
      "Speed: 0.0ms preprocess, 6.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.8ms\n",
      "Speed: 1.0ms preprocess, 12.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 1.7ms preprocess, 12.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.1ms\n",
      "Speed: 2.0ms preprocess, 14.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 10.8ms\n",
      "Speed: 3.0ms preprocess, 10.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.1ms\n",
      "Speed: 1.8ms preprocess, 11.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.1ms\n",
      "Speed: 2.0ms preprocess, 8.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.6ms\n",
      "Speed: 1.0ms preprocess, 11.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 5.8ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.3ms\n",
      "Speed: 1.0ms preprocess, 12.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.0ms\n",
      "Speed: 1.4ms preprocess, 12.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 3.6ms\n",
      "Speed: 1.0ms preprocess, 3.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.8ms\n",
      "Speed: 2.1ms preprocess, 11.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 1.0ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 14.0ms\n",
      "Speed: 1.4ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.2ms\n",
      "Speed: 0.0ms preprocess, 6.2ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.9ms\n",
      "Speed: 0.0ms preprocess, 9.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 7.4ms\n",
      "Speed: 0.0ms preprocess, 7.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.9ms\n",
      "Speed: 0.9ms preprocess, 13.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.7ms\n",
      "Speed: 0.0ms preprocess, 12.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.9ms\n",
      "Speed: 2.1ms preprocess, 13.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.8ms\n",
      "Speed: 0.0ms preprocess, 6.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 19.4ms\n",
      "Speed: 0.0ms preprocess, 19.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.8ms\n",
      "Speed: 1.9ms preprocess, 13.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.9ms\n",
      "Speed: 2.0ms preprocess, 12.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 13.3ms\n",
      "Speed: 1.3ms preprocess, 13.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 12.6ms\n",
      "Speed: 1.5ms preprocess, 12.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 5.8ms\n",
      "Speed: 2.0ms preprocess, 5.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 9.3ms\n",
      "Speed: 1.0ms preprocess, 9.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 6.6ms\n",
      "Speed: 7.1ms preprocess, 6.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 11.7ms\n",
      "Speed: 10.6ms preprocess, 11.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Loop through the video frames\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cap\u001b[38;5;241m.\u001b[39misOpened():\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# Read a frame from the video\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m     success, frame \u001b[38;5;241m=\u001b[39m cap\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# Run YOLOv8 inference on the frame\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m#results = model.(frame)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mtrack(frame, persist\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Open the video file\n",
    "#cap = cv2.VideoCapture(video_path)\n",
    "cap = cv2.VideoCapture(rtsp, cv2.CAP_FFMPEG)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        #results = model.(frame)\n",
    "        results = model.track(frame, persist=True)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51e76db-7e65-4110-8813-971a6e11d6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AAI3001",
   "language": "python",
   "name": "aai3001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
